{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "#methodology; TLDR: idempotent write op with job-id as primary key\n",
    "# 1. use cvs as database\n",
    "# 2. load csv in cache\n",
    "# 3. scrape & parse linkedin jobs\n",
    "# 4. look up jobid, omit if exists in cache, add to cache and jobs_to_add array\n",
    "# 5. write jobs_to_add back to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurations\n",
    "#base_url_prefix = \"https://www.linkedin.com/jobs/search?keywords=software%20engineer%20OR%20engineering%20manager&location=United%20States&pageNum=0&start=\"\n",
    "base_url_prefix = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=software%20engineer%20OR%20engineering%20manager&location=United%2BStates&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&start=\"\n",
    "row_increment_default = 10\n",
    "max_row_default = 2000\n",
    "EM_AS_ENG_MULTIPLIER=3\n",
    "csv_name=\"linkedin-job-scraper-database.csv\"\n",
    "csv_columns=['job_id','company','job_type','title','location','link','date']\n",
    "\n",
    "class DebugLevel(Enum):\n",
    "    WARN = 0\n",
    "    GENERAL = 1\n",
    "    GRANULAR = 2\n",
    "    \n",
    "debug_level = DebugLevel.WARN\n",
    "debug_company=\"\"\n",
    "ignore_list=[\"SynergisticIT\",\"Jobs Malaysia - Two95 HR HUB\",\"Kforce Inc\",\"ICONMA\",\"Get It Recruit - Information Technology\",\"Team Remotely Inc\",\"Ampcus Inc\",\"Genesis10\",\"Intellectt Inc\",\"Stealth\",\"LanceSoft, Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializations\n",
    "jobs={} # updated cache, won't be written back to csv\n",
    "jobs_to_add=[] # write-back as additions, strictly as a write buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_in_cache(reader):\n",
    "    dups_detection=[]\n",
    "    for row in reader: #reader knows first row is headers\n",
    "        key = row['job_id']\n",
    "        \n",
    "        if key in dups_detection:\n",
    "            print(f\"duplicate detected: job_id={key}\")\n",
    "        else:\n",
    "            dups_detection.append(key)\n",
    "            \n",
    "        value = {k: v for k, v in row.items() if k != 'job_id'}\n",
    "        jobs[key] = value\n",
    "\n",
    "    print(f\"{len(jobs)} rows read from csv\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(csv_name):\n",
    "    with open(csv_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile) #this will create new file if not exist\n",
    "        writer.writerow(csv_columns)\n",
    "else:\n",
    "    with open(csv_name, 'r+', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        load_csv_in_cache(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,max_row_default,row_increment_default):\n",
    "    base_url = f\"{base_url_prefix}{i}\"\n",
    "    response = requests.get(base_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        job_listings = soup.find_all('div', {'class':'job-search-card'})\n",
    "        for job in job_listings:\n",
    "            try:\n",
    "                date = job.find('time', {'class':'job-search-card__listdate'}).attrs['datetime']\n",
    "            except AttributeError:\n",
    "                date = job.find('time', {'class':'job-search-card__listdate--new'}).attrs['datetime']\n",
    "            \n",
    "            title = job.find('h3', {'class': 'base-search-card__title'}).text.strip()\n",
    "            job_type = 'em' if 'manager' in title.lower() else 'eng'\n",
    "            company = job.find('a', {'class': 'hidden-nested-link'}).text.strip()\n",
    "            \n",
    "            if company in ignore_list: #these are staffing companies\n",
    "                continue\n",
    "            \n",
    "            location = job.find('span', {'class': 'job-search-card__location'}).text.strip()\n",
    "            link = job.find('a', {'class': 'base-card__full-link'}).attrs['href']\n",
    "            pattern = r\"(.*-)(\\d+)\"\n",
    "            job_id = re.search(pattern,link).group(2)\n",
    "\n",
    "            #debug\n",
    "            if debug_level==DebugLevel.GRANULAR and debug_company != \"\" and company == debug_company:\n",
    "                print(f\"id:{job_id},title:{title},job_type:{job_type},link:{link}\")\n",
    "            elif debug_level==DebugLevel.GENERAL:\n",
    "                print(f\"id:{job_id},title:{title},job_type:{job_type},company:{company}\")\n",
    "            \n",
    "            #look up job_id, omit if cache hit, add to cache and jobs_to_add array if cache miss\n",
    "            if len(jobs_to_add) > 0 and job_id in jobs_to_add[0]: # exists in delta\n",
    "                if debug_level==DebugLevel.WARN: #if item offset is set efficiently this printline should never show\n",
    "                    print(f\"we've seen {company}-{job_id}\")\n",
    "                continue\n",
    "            elif jobs.get(job_id,\"\") != \"\": # cache hit: exists in database\n",
    "                continue\n",
    "            else:                    \n",
    "                jobs.setdefault(job_id,{\n",
    "                    csv_columns[1]: company,\n",
    "                    csv_columns[2]: job_type,\n",
    "                    csv_columns[3]: title,\n",
    "                    csv_columns[4]: location,\n",
    "                    csv_columns[5]: link,\n",
    "                    csv_columns[6]: date\n",
    "                })\n",
    "                jobs_to_add.append([job_id,company,job_type,title,location,link,date])\n",
    "                \n",
    "    else:\n",
    "        print(\"Failed to fetch job listings.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_name, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Append all new rows\n",
    "    writer.writerows(jobs_to_add)\n",
    "    print(f\"{len(jobs_to_add)} jobs added\")\n",
    "jobs_to_add=[] #reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(jobs).T\n",
    "df_eng=df[df['job_type']=='eng'].groupby(['company'])['date'].agg(['count','max'])\n",
    "df_em=df[df['job_type']=='em'].groupby(['company'])['date'].agg(['count','max'])\n",
    "df_em['count']=df_em['count'].apply(lambda x: x*EM_AS_ENG_MULTIPLIER)\n",
    "df2=pd.merge(df_eng,df_em,on='company',how='outer')\n",
    "df2 = df2.fillna(0)\n",
    "df2['count']=df2['count_x']+df2['count_y']\n",
    "df2['max']=df2.apply(lambda row: max(str(row['max_x']),str(row['max_y'])), axis=1)\n",
    "p95count=df2['count'].quantile(.95)\n",
    "print(f\"p95count:{p95count}\")\n",
    "df2[df2['count']>p95count].sort_values('count',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
